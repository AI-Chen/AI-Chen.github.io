---
layout: post
title: HrNet V2总结
categories: 语义分割优秀论文阅读
tags: 语义分割优秀论文阅读
author: Chen
description: HrNet V2总结
---

**摘要**：为了提高语义分割的精度，目前主流的趋势是先降低分辨率提取高级的语义特征，再采取多样的方法从低分辨率表示恢复到高分辨表示。在本文中则不然，HrNet V2在整个过程中都保持着高分辨率的表示。该模型分为先后五个阶段，第一阶段下采样到输入图像原有尺寸的1/4。随后，每一个阶段的开始添加从高分辨率通过下采样得到的低分辨率子网，结束前进行重复的多尺度融合，使得每一个分辨率可以重复的从其他分辨率获取信息。最后在第五阶段将所有的并行低分辨率子网的输出上采样到高分辨率子网的尺寸大小，然后通过连接所有的子网的表示获取到具有丰富信息的高分辨率表示。该模型在许多典型的语义分割数据集上都取得了更为精确的分割结果。

----

### 1、现有方法
&emsp;&emsp;计算最后的heatmap表示有两条主线。第一种是从网络（例如，ResNet）输出的低分辨率表示中恢复高分辨率表示，并且可选地恢复中间中等分辨率表示，例如Hourglass ，SegNet，DeconvNet，U-Net，和encoder-decoder。 另一个是通过高分辨率卷积保持高分辨率表示，并用并行的低分辨率卷积加强高分辨率表示。 此外，空洞卷积用于替换分类网络中的一些跨步卷积和相关的常规卷积，以计算中等分辨率表示。<br>
&emsp;&emsp;主线一的的典型方法包括以下4种：<br>
![从低分辨率表示恢复高分辨率表示](//assets/images/HrNet/HrNet1.JPG)<br>
&emsp;&emsp;* a:对称结构。如U-Net等。先下采样，再上采样，使用跳层连接恢复下采样的信息。<br>
&emsp;&emsp;* b:级联金字塔。<br>
&emsp;&emsp;* c:先下采样，再使用转置卷积进行上采样。没有跳层连接<br>
&emsp;&emsp;* d:扩张卷积。增大感受野，在可以减少下采样的次数的同时直接可以不进行跳层连接而直接进行上采样<br>
&emsp;&emsp;本文正是沿着第二条主线进行的研究。高分辨率表示是在整个过程维持高分辨率，通常是通过将多分辨率（从高分辨率到低分辨率）并行卷积与并行卷积中的重复信息交换连接而形成的网络。代表作品包括GridNet ，卷积神经结构，相互连接的CNN ，以及最近开发的高分辨率网络（HRNet）。下面的将对在HrNet上做出很少修改，增加较小的计算开销，却较大的提升了分割准确度的HrNet V2做出详细的介绍。

----
### 2、HrNet V2方法概述
#### 2.1、HrNet V2框架
&emsp;&emsp;HrNet通过连接并行的不同分辨率表示和重复进行多尺度融合来维持高分辨率表示，由此产生的高分辨率表示不仅信息丰富而且空间精确。HrNet V2对HrNet进行了简单的修改。此修改增加了较小的开销，但是有着更强的高分辨率表示。如下图所示是HrNet V2的整体框架：
![HrNet V2框架](../assets/images/HrNet/HrNet2.JPG)<br>
&emsp;&emsp;整个模块分为5个阶段：stem、stage1、stage2、stage3、stage4.在作者提供的开源代码中，将产生低分辨分支的功能以及重复的多尺度融合功能进行了分离，产生低分辨分支的功能在stage1、stage2、stage3阶段开头，重复的多尺度融合功能在stage1、stage2、stage3阶段的结尾。所以，在上图中，我将每一阶段的区分线画在了图中交叉线的中间。竖线1的左方是原始的HrNet表示。它直接输出stage3中的最上方的高分辨率表示，使其作为最后的heatmap。而HrNet V2则在其基础上添加了竖线1右边的部分。它首先将三个并行低分辨率子网的输出上采样到高分辨率子网的尺寸大小，然后通过简单的连接操作连接同样尺寸大小的四个分支的结果。最后将连接的结果通过1×1的卷积将通道数转变为语义分割的类别数目从而得到最后的结果。下面详细的介绍每一个阶段的具体处理步骤:<br>
&emsp;&emsp;1）**stem**。stem中完成的三个箭头代表着3个不同的处理。前两个处理使用步长为2的3×3卷积操作将输入图像卷积两次。从而使得图像的高（H）和宽（W）变为H/4与W/4的大小。随后的第三个处理使用4个Basicblock或者bottleblock进行处理，起到提取特征的作用。随后得到的输出（大小为[H/4，W/4，256]）被输入stage1中。<br>
&emsp;&emsp;2）**stage1**。首先在上一阶段的基础上产生一个低分辨率的分支。然后每一个分支分别利用4个Basicblock或者bottleblock进行特征提取。最后进行重复多尺度融合得到最后的输出。随后将得到的输出（大小分别为[H/4，W/4，32]，[H/8，W/8，64]）输入stage2中<br>
&emsp;&emsp;3）**stage2**。<br>首先在上一阶段的基础上产生一个低分辨率的分支。然后每一个分支分别利用4个Basicblock或者bottleblock进行特征提取。最后进行重复多尺度融合得到最后的输出。随后将得到的输出（大小分别为[H/4，W/4，32]，[H/8，W/8，64]，[H/16，W/16，128]）输入stage3中<br>
&emsp;&emsp;4）**stage3**。首先在上一阶段的基础上产生一个低分辨率的分支。然后每一个分支分别利用4个Basicblock或者bottleblock进行特征提取。最后进行重复多尺度融合得到最后的输出。随后将得到的输出（大小分别为[H/4，W/4，32]，[H/8，W/8，64]，[H/16，W/16，128]，[H/32，W/32，256]）输入stage3中<br>
&emsp;&emsp;5）**stage4**。这个阶段的功能在本节开始时已经介绍，这里不加赘述
#### 2.2、重复的多尺度融合
&emsp;&emsp;我们以stage2阶段最后进行的重复多尺度融合融合为例进行介绍。其他阶段的多尺度融合原理与其一致。在stage2进行重复多尺度融合前，存在3个不同分辨率表示的分支。所以，该阶段的多尺度融合如下图所示，需要3个步骤：
![重复的多尺度融合](../assets/images/HrNet/HrNet3.JPG)<br>
&emsp;&emsp;图中左边进行的处理是：首先将两个低分辨率表示的分支通过1×1的卷积变换到高分辨率同样的通道数。然后进行上采样，使得两个低分辨率表示的尺寸大小与高分辨率表示一致（H/4,W/4）。最后后，将三个不同分辨率表示求和得到了最后融合后的高分辨率表示。<br>
&emsp;&emsp;图中中间进行的处理是：首先将高分辨率表示的分支通过步长为2的3×3的卷积变换到与中间分辨率表示的尺寸（H/8,W/8）与通道数一样大小。然后，将先后通过1×1卷积与上采样操作将最低分辨率表示同样调整到中间分辨率表示的尺寸与通道数一样大小。最后，将三个不同分辨率表示求和得到了最后融合后的中间分辨率表示。<br>
&emsp;&emsp;图中右边进行的处理是：首先将两个高分辨率表示的分支通过步长为2的3×3的卷积变换到与最低分辨率表示的尺寸（H/16,W/16）与通道数一样大小。最后，将三个不同分辨率表示求和得到了最后融合后的最低分辨率表示。

----
### 3、代码详解(代码开源地址：https://github.com/HRNet/HRNet-Semantic-Segmentation)
#### 3.1、代码整体感知
&emsp;&emsp;开源代码的整体结构如图所示：
![重复的多尺度融合](../assets/images/HrNet/HrNet4.JPG)<br>
&emsp;&emsp;其中模型的编写以及超参数的设置分别存放于lib/models/seg_hrnet.py与lib/config/models.py中。seg_hrnet.py中包括Blockblock、bottleblock、HighResolutionModule、HighResolutionNet四个类以及一个封装好的名为conv3x3的函数用于3*3的卷积。其中HighResolutionNet定义了整个HrNet V2模块。HighResolutionModule是HighResolutionNet要调用的多尺度特征融合的模型。Blockblock、bottleblock是两个提取特征的模块。
#### 3.2、Basic block与bottle block
&emsp;&emsp;这两个模块是HrNet V2中要用到的特征提取模块。它们都是ResNet网络中所用到的经典的残差模块。<br>
![重复的多尺度融合](../assets/images/HrNet/HrNet5.JPG)<br>
&emsp;&emsp;Basic block模块搭建结构如上图左边所示：
>* 每一个3×3的卷积后都连接BN层进行批归一化；<br>
* 进入残差连接前的3×3的卷积后只接入BN层而不使用Relu函数，避免求和之后的特征都为正数，保持了特征的多样化；<br>
* 跳层连接：1）当模块输入的通道数与经过卷积处理后的特征向量通道数一致时，直接相加；2）当通道不一致时（一般发生于通道分辨率降低之后，同分辨率通道数一般一致），需要使用1×1的卷积（stride=2，使得分辨率降低）对原始输入数据进行处理，使其通道数与尺寸大小即分辨率经过两次3×3卷积处理后的残差支路特征一致。随后接入BN层，处理后不用ReLU而直接与残差支路特征求和。<br>

```
    class BasicBlock(nn.Module):
        expansion = 1

        def __init__(self, inplanes, planes, stride=1, downsample=None):
            super(BasicBlock, self).__init__()
            self.conv1 = conv3x3(inplanes, planes, stride)
            self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)
            self.relu = nn.ReLU(inplace=False)
            self.conv2 = conv3x3(planes, planes)
            self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)
            self.downsample = downsample
            self.stride = stride

        def forward(self, x):
            residual = x

            out = self.conv1(x)
            out = self.bn1(out)
            out = self.relu(out)

            out = self.conv2(out)
            out = self.bn2(out)

            if self.downsample is not None:
                residual = self.downsample(x)

            out = out + residual
            out = self.relu(out)

            return out
```
&emsp;&emsp;Basic block模块搭建结构如上图右边所示：
>* 首先使用1×1的卷积降低通道数从而减少计算开销，再使用3×3的卷积进行特征提取，最后再使用1×1的卷积恢复通道数；<br>
* 每一个卷积后都要接入BN层；<br>
* 进入残差连接前的1×1的卷积后只接入BN层而不使用Relu函数，避免求和之后的特征都为正数，保持了特征的多样化；<br>
跳层连接：1）当模块输入的通道数与经过卷积处理后的特征向量通道数一致时，直接相加；2）当通道不一致时（一般发生于通道分辨率降低之后，同分辨率通道数一般一致），需要使用1×1的卷积（stride=2，使得分辨率降低）对原始输入数据进行处理，使其通道数与尺寸大小即分辨率经过1×1，3×3，1×1卷积处理后的残差支路特征一致。随后接入BN层，处理后不用ReLU而直接与残差支路特征求和。<br>

```
      class Bottleneck(nn.Module):
          expansion = 4
          def __init__(self, inplanes, planes, stride=1, downsample=None):
              super(Bottleneck, self).__init__()
              self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
              self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)
              self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
                                     padding=1, bias=False)
              self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)
              self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,
                                     bias=False)
              self.bn3 = BatchNorm2d(planes * self.expansion,
                                     momentum=BN_MOMENTUM)
              self.relu = nn.ReLU(inplace=False)
              self.downsample = downsample
              self.stride = stride
          def forward(self, x):
              residual = x
              out = self.conv1(x)
              out = self.bn1(out)
              out = self.relu(out)
              out = self.conv2(out)
              out = self.bn2(out)
              out = self.relu(out)
              out = self.conv3(out)
              out = self.bn3(out)
              if self.downsample is not None:
                  residual = self.downsample(x)
              out = out + residual
              out = self.relu(out)
              return out
```
#### 3.3、HighResolutionModule
&emsp;&emsp;这个类的功能是对每一个分辨率表示的分支进行特征提取。提取完毕之后进行分支之间的重复多尺度融合。它的业务逻辑是：当只包含一个分支的时候，便提取该分支的特征，并且最后没有融合的模块，直接返回提取结果；当分支的数目大于1时，先对每一个分支分别进行特征提取，然后对特征提取结果进行特征融合，最后再返回融合结果。以下是HighResolutionModule类中主要函数的作用：<br>
&emsp;&emsp;1)\_check_branches:用于判断num_branches和num_blocks,num_inchannels,num_channels三者的长度是否一致，不一致则终止程序并报错；<br>
&emsp;&emsp;2)\_make_one_branch:对一个分支进行特征提取。在单个分支中，特征提取使用到数目为num_blocks的basicblock或者bottleblock（实际在开源代码中采用到的是basicblock，后续讲解也采用basicblock）。<br>

>* 先判断输入与输出通道是否一致（即num_inchannels[branch_index]是否等于等于num_channels[branch_index]\*block.expansion，其中block.expansion是通道扩张率），不一致则使downsample成为一个1×1的卷积进行通道数的调整。调整后接入BN层。
* 一个分支中采用num_blocks个。第一个block需要考虑到通道数的变化，所以单独处理。后续的block处理完全一致，所以后续block的执行使用循环语句进行。

&emsp;&emsp;3)\_make_branches:循环调用\_make_one_branch函数，从而对当前阶段的每一个分支都使用num_blocks个basicblock或者bottleblock进行特征提取。<br>
&emsp;&emsp;4)\_make_fuse_layers:封装了进行重复多尺度特征融合的代码。它的业务逻辑如下：<br>
>* 该函数主要是一个双层循环。
* 外循环for i in range(num_branches if self.multi_scale_output else 1):表示如果分支数等于1，则不需要融合，不进入循环直接返回输入的分辨率表示。如果分支数大于1，则循环num_branches次（即循环次数为分支的数目）。
* 进入内部循环之后：<br>
&emsp;&emsp;如果 **j>i**。也就是说比i分支分辨率还要低的j分支之间的融合。这个时候就将j分支通过1×1的卷积（卷积后要用BN处理）以及上采样（方式为最邻近差值法）转换到与i分支的分辨率与通道数相同并将二者进行求和。当j>i条件的循环被全部执行完毕之后，所有的比i分辨率低的分支都与i进行了融合。<br>
![j>i](../assets/images/HrNet/HrNet6.JPG)<br>
&emsp;&emsp;如果 **j=i**。此时由于与本身融和无意义，所以不做处理。<br>
&emsp;&emsp;如果 **j<i**。与j>i的情况相反，这一部分的意义在于使得所有比i分支分辨率高的分支与其进行融合。这要求j分支要进行卷积运算使得其分辨率与通道数变得一致。j分支的分辨率调整要经过j-i次卷积运算。所以在这一部分再次出现了一个循环for k in range(i-j):来执行重复的卷积操作。由于最后一次卷积操作不执行Relu操作，所以在循环中用if语句将其单独挑选出来执行。

```
class HighResolutionModule(nn.Module):
    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,
                 num_channels, fuse_method, multi_scale_output=True):
        super(HighResolutionModule, self).__init__()
        self._check_branches(
            num_branches, blocks, num_blocks, num_inchannels, num_channels)

        self.num_inchannels = num_inchannels
        self.fuse_method = fuse_method
        self.num_branches = num_branches

        self.multi_scale_output = multi_scale_output

        self.branches = self._make_branches(
            num_branches, blocks, num_blocks, num_channels)
        self.fuse_layers = self._make_fuse_layers()
        self.relu = nn.ReLU(inplace=False)

    def _check_branches(self, num_branches, blocks, num_blocks,
                        num_inchannels, num_channels):
        if num_branches != len(num_blocks):
            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(
                num_branches, len(num_blocks))
            logger.error(error_msg)
            raise ValueError(error_msg)

        if num_branches != len(num_channels):
            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(
                num_branches, len(num_channels))
            logger.error(error_msg)
            raise ValueError(error_msg)

        if num_branches != len(num_inchannels):
            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(
                num_branches, len(num_inchannels))
            logger.error(error_msg)
            raise ValueError(error_msg)

    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,
                         stride=1):
        downsample = None
        if stride != 1 or \
           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.num_inchannels[branch_index],
                          num_channels[branch_index] * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                BatchNorm2d(num_channels[branch_index] * block.expansion,
                            momentum=BN_MOMENTUM),
            )

        layers = []
        layers.append(block(self.num_inchannels[branch_index],
                            num_channels[branch_index], stride, downsample))
        self.num_inchannels[branch_index] = \
            num_channels[branch_index] * block.expansion
        for i in range(1, num_blocks[branch_index]):
            layers.append(block(self.num_inchannels[branch_index],
                                num_channels[branch_index]))

        return nn.Sequential(*layers)

    def _make_branches(self, num_branches, block, num_blocks, num_channels):
        branches = []

        for i in range(num_branches):
            branches.append(
                self._make_one_branch(i, block, num_blocks, num_channels))

        return nn.ModuleList(branches)

    def _make_fuse_layers(self):
        if self.num_branches == 1:
            return None

        num_branches = self.num_branches
        num_inchannels = self.num_inchannels
        fuse_layers = []
        for i in range(num_branches if self.multi_scale_output else 1):
            fuse_layer = []
            for j in range(num_branches):
                if j > i:
                    fuse_layer.append(nn.Sequential(
                        nn.Conv2d(num_inchannels[j],
                                  num_inchannels[i],
                                  1,
                                  1,
                                  0,
                                  bias=False),
                        BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))
                elif j == i:
                    fuse_layer.append(None)
                else:
                    conv3x3s = []
                    for k in range(i-j):
                        if k == i - j - 1:
                            num_outchannels_conv3x3 = num_inchannels[i]
                            conv3x3s.append(nn.Sequential(
                                nn.Conv2d(num_inchannels[j],
                                          num_outchannels_conv3x3,
                                          3, 2, 1, bias=False),
                                BatchNorm2d(num_outchannels_conv3x3,
                                            momentum=BN_MOMENTUM)))
                        else:
                            num_outchannels_conv3x3 = num_inchannels[j]
                            conv3x3s.append(nn.Sequential(
                                nn.Conv2d(num_inchannels[j],
                                          num_outchannels_conv3x3,
                                          3, 2, 1, bias=False),
                                BatchNorm2d(num_outchannels_conv3x3,
                                            momentum=BN_MOMENTUM),
                                nn.ReLU(inplace=False)))
                    fuse_layer.append(nn.Sequential(*conv3x3s))
            fuse_layers.append(nn.ModuleList(fuse_layer))

        return nn.ModuleList(fuse_layers)

    def get_num_inchannels(self):
        return self.num_inchannels

    def forward(self, x):
        if self.num_branches == 1:
            return [self.branches[0](x[0])]

        for i in range(self.num_branches):
            x[i] = self.branches[i](x[i])

        x_fuse = []
        for i in range(len(self.fuse_layers)):
            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])
            for j in range(1, self.num_branches):
                if i == j:
                    y = y + x[j]
                elif j > i:
                    width_output = x[i].shape[-1]
                    height_output = x[i].shape[-2]
                    y = y + F.interpolate(
                        self.fuse_layers[i][j](x[j]),
                        size=[height_output, width_output],
                        mode='bilinear')
                else:
                    y = y + self.fuse_layers[i][j](x[j])
            x_fuse.append(self.relu(y))

        return x_fuse
```
##### 3.4、HighResolutionNet
&emsp;&emsp;HighResolutionNet是对模型总的定义。其所涉及的超参数放置于models.py中，具体参数设置如下：

```
# high_resoluton_net related params for segmentation
HIGH_RESOLUTION_NET = CN()
HIGH_RESOLUTION_NET.PRETRAINED_LAYERS = ['*']
HIGH_RESOLUTION_NET.STEM_INPLANES = 64
HIGH_RESOLUTION_NET.FINAL_CONV_KERNEL = 1
HIGH_RESOLUTION_NET.WITH_HEAD = True

HIGH_RESOLUTION_NET.STAGE2 = CN()
HIGH_RESOLUTION_NET.STAGE2.NUM_MODULES = 1
HIGH_RESOLUTION_NET.STAGE2.NUM_BRANCHES = 2
HIGH_RESOLUTION_NET.STAGE2.NUM_BLOCKS = [4, 4]
HIGH_RESOLUTION_NET.STAGE2.NUM_CHANNELS = [32, 64]
HIGH_RESOLUTION_NET.STAGE2.BLOCK = 'BASIC'
HIGH_RESOLUTION_NET.STAGE2.FUSE_METHOD = 'SUM'

HIGH_RESOLUTION_NET.STAGE3 = CN()
HIGH_RESOLUTION_NET.STAGE3.NUM_MODULES = 1
HIGH_RESOLUTION_NET.STAGE3.NUM_BRANCHES = 3
HIGH_RESOLUTION_NET.STAGE3.NUM_BLOCKS = [4, 4, 4]
HIGH_RESOLUTION_NET.STAGE3.NUM_CHANNELS = [32, 64, 128]
HIGH_RESOLUTION_NET.STAGE3.BLOCK = 'BASIC'
HIGH_RESOLUTION_NET.STAGE3.FUSE_METHOD = 'SUM'

HIGH_RESOLUTION_NET.STAGE4 = CN()
HIGH_RESOLUTION_NET.STAGE4.NUM_MODULES = 1
HIGH_RESOLUTION_NET.STAGE4.NUM_BRANCHES = 4
HIGH_RESOLUTION_NET.STAGE4.NUM_BLOCKS = [4, 4, 4, 4]
HIGH_RESOLUTION_NET.STAGE4.NUM_CHANNELS = [32, 64, 128, 256]
HIGH_RESOLUTION_NET.STAGE4.BLOCK = 'BASIC'
HIGH_RESOLUTION_NET.STAGE4.FUSE_METHOD = 'SUM'

MODEL_EXTRAS = {
    'seg_hrnet': HIGH_RESOLUTION_NET,
}
```
&emsp;&emsp;模型一共分为stem、stage1、stage2、stage3、stage4五个阶段。stem所做的工作是将原始输入图像的分辨率减小至[H/4,W/4],并将通道数变为256。stage1、stage2、stage3这三个阶段在逐步增加低分辨率分支（调用\_make_transition_layer函数实现）的同时，通过重复的多尺度融合（调用HighResolutionModule类实现）交换各个分支上不同分辨率表示的信息。这样使得各分支的分辨率表示更加准确。stage4将所有低分辨率分支的表示上采样到最高分辨率表示的尺寸大小，并通过3×3的卷积使得所有分辨率表示的通道数一致.最后通过1*1的卷积将通道数调整至具体语义分割任务类别的数目。<br>
>* \_make_layer:在stem阶段调用。使用4个Basicblock或者bottleblock作为特征提取块搭建（开源代码中使用的是bottleblock搭建），用于特征提取。由于开始要对通道数进行变换（64到256），第一个特征提取块单独搭建。后面的3个特征提取块由于不需要考虑通道的变化（均为256），所以采用循环语句循环搭建。<br>
* \_make_trasition_layer:在stage1、stage2、stage3中调用。作用在于在每一个阶段开始前增加一个低分辨率分支。比如在stage1中，上一阶段的分辨率表示为[H/4,W/4,256]。经过\_make_trasition_layer的处理后变为两个分支：[H/4,W/4,32]、[H/8,W/8,64].
* \_make_stage:在stage1、stage2、stage3中调用.作用在于通过它调用HighResolutionModule类从而实现每一个分支的特征提取与分支之间的多尺度融合。

```
class HighResolutionNet(nn.Module):

    def __init__(self, config, **kwargs):
        extra = config.MODEL.EXTRA
        super(HighResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,
                               bias=False)
        self.bn1 = BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,
                               bias=False)
        self.bn2 = BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=False)

        self.layer1 = self._make_layer(Bottleneck, 64, 64, 4)

        self.stage2_cfg = extra['STAGE2']
        num_channels = self.stage2_cfg['NUM_CHANNELS']
        block = blocks_dict[self.stage2_cfg['BLOCK']]
        num_channels = [
            num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(
            self.stage2_cfg, num_channels)

        self.stage3_cfg = extra['STAGE3']
        num_channels = self.stage3_cfg['NUM_CHANNELS']
        block = blocks_dict[self.stage3_cfg['BLOCK']]
        num_channels = [
            num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(
            pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(
            self.stage3_cfg, num_channels)

        self.stage4_cfg = extra['STAGE4']
        num_channels = self.stage4_cfg['NUM_CHANNELS']
        block = blocks_dict[self.stage4_cfg['BLOCK']]
        num_channels = [
            num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(
            pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True)

        last_inp_channels = np.int(np.sum(pre_stage_channels))

        self.last_layer = nn.Sequential(
            nn.Conv2d(
                in_channels=last_inp_channels,
                out_channels=last_inp_channels,
                kernel_size=1,
                stride=1,
                padding=0),
            BatchNorm2d(last_inp_channels, momentum=BN_MOMENTUM),
            nn.ReLU(inplace=False),
            nn.Conv2d(
                in_channels=last_inp_channels,
                out_channels=config.DATASET.NUM_CLASSES,
                kernel_size=extra.FINAL_CONV_KERNEL,
                stride=1,
                padding=1 if extra.FINAL_CONV_KERNEL == 3 else 0)
        )

    def _make_transition_layer(
            self, num_channels_pre_layer, num_channels_cur_layer):
        num_branches_cur = len(num_channels_cur_layer)
        num_branches_pre = len(num_channels_pre_layer)

        transition_layers = []
        for i in range(num_branches_cur):
            if i < num_branches_pre:
                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:
                    transition_layers.append(nn.Sequential(
                        nn.Conv2d(num_channels_pre_layer[i],
                                  num_channels_cur_layer[i],
                                  3,
                                  1,
                                  1,
                                  bias=False),
                        BatchNorm2d(
                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),
                        nn.ReLU(inplace=False)))
                else:
                    transition_layers.append(None)
            else:
                conv3x3s = []
                for j in range(i+1-num_branches_pre):
                    inchannels = num_channels_pre_layer[-1]
                    outchannels = num_channels_cur_layer[i] \
                        if j == i-num_branches_pre else inchannels
                    conv3x3s.append(nn.Sequential(
                        nn.Conv2d(
                            inchannels, outchannels, 3, 2, 1, bias=False),
                        BatchNorm2d(outchannels, momentum=BN_MOMENTUM),
                        nn.ReLU(inplace=False)))
                transition_layers.append(nn.Sequential(*conv3x3s))

        return nn.ModuleList(transition_layers)

    def _make_layer(self, block, inplanes, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),
            )

        layers = []
        layers.append(block(inplanes, planes, stride, downsample))
        inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(inplanes, planes))

        return nn.Sequential(*layers)

    def _make_stage(self, layer_config, num_inchannels,
                    multi_scale_output=True):
        num_modules = layer_config['NUM_MODULES']
        num_branches = layer_config['NUM_BRANCHES']
        num_blocks = layer_config['NUM_BLOCKS']
        num_channels = layer_config['NUM_CHANNELS']
        block = blocks_dict[layer_config['BLOCK']]
        fuse_method = layer_config['FUSE_METHOD']

        modules = []
        for i in range(num_modules):
            # multi_scale_output is only used last module
            if not multi_scale_output and i == num_modules - 1:
                reset_multi_scale_output = False
            else:
                reset_multi_scale_output = True
            modules.append(
                HighResolutionModule(num_branches,
                                      block,
                                      num_blocks,
                                      num_inchannels,
                                      num_channels,
                                      fuse_method,
                                      reset_multi_scale_output)
            )
            num_inchannels = modules[-1].get_num_inchannels()

        return nn.Sequential(*modules), num_inchannels

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.layer1(x)

        x_list = []
        for i in range(self.stage2_cfg['NUM_BRANCHES']):
            if self.transition1[i] is not None:
                x_list.append(self.transition1[i](x))
            else:
                x_list.append(x)
        y_list = self.stage2(x_list)

        x_list = []
        for i in range(self.stage3_cfg['NUM_BRANCHES']):
            if self.transition2[i] is not None:
                x_list.append(self.transition2[i](y_list[-1]))
            else:
                x_list.append(y_list[i])
        y_list = self.stage3(x_list)

        x_list = []
        for i in range(self.stage4_cfg['NUM_BRANCHES']):
            if self.transition3[i] is not None:
                x_list.append(self.transition3[i](y_list[-1]))
            else:
                x_list.append(y_list[i])
        x = self.stage4(x_list)

        # Upsampling
        x0_h, x0_w = x[0].size(2), x[0].size(3)
        x1 = F.upsample(x[1], size=(x0_h, x0_w), mode='bilinear')
        x2 = F.upsample(x[2], size=(x0_h, x0_w), mode='bilinear')
        x3 = F.upsample(x[3], size=(x0_h, x0_w), mode='bilinear')

        x = torch.cat([x[0], x1, x2, x3], 1)

        x = self.last_layer(x)

        return x

    def init_weights(self, pretrained='',):
        logger.info('=> init weights from normal distribution')
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.normal_(m.weight, std=0.001)
            elif isinstance(m, InPlaceABNSync):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
        if os.path.isfile(pretrained):
            pretrained_dict = torch.load(pretrained)
            logger.info('=> loading pretrained model {}'.format(pretrained))
            model_dict = self.state_dict()
            pretrained_dict = {k: v for k, v in pretrained_dict.items()
                               if k in model_dict.keys()}
            for k, _ in pretrained_dict.items():
                logger.info(
                    '=> loading {} pretrained model {}'.format(k, pretrained))
            model_dict.update(pretrained_dict)
            self.load_state_dict(model_dict)
```

----
### 4、总结
&emsp;&emsp;HrNet V2的创新之处在于在整个过程中均保持这高分辨率表示。这使得低级的空间信息在该网络上得以充分的保留。同时，为了获取更过的高级语义信息，HrNet V2在每个阶段逐步增加低分辨率表示分支，并进行重复的多尺度特征融合。这使得高分辨率表示中也具有很强的高级语义特征。这样，分割结果与其它优秀的模型相比，HrNet V2在空间上更加精确。<br>
&emsp;&emsp;个人在读完这一篇文章后，比较感慨于作者反其道而行之的想法。大多数模型将高分辨率表示作为辅助数据添加到低分辨率的上采样过程中，从而使得结果更加精确。而作者则以高分辨率表示为主，使得低分辨率的表示成为了辅助数据。这样的想法不得不令人赞叹。<br>
&emsp;&emsp;另外，我参照论文以及作者的开源代码，复现了HrNet V2的Tensorflow版本（地址：https://github.com/AI-Chen/HRNet-V2）

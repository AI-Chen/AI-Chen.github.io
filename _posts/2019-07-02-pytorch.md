---
layout: post
title:  pytorch学习总结
---
&emsp;&emsp;在过去4天的时间内，粗略的学习了《PyTorch_tutorial_0.0.4_余霆嵩》。这篇文章从cifar-10数据集的识别为目的，讲解了如何使用pytorch进行数据集的读取、模型的构建、损失函数与优化器的选择、可视化模型。在此基础上，为了进一步使得自己入门pytorch，我使用它构建了ResNet34模型，并选择了合适的损失函数、优化器训练该模型对cifar10数据集进行识别分类，同时在tensorboard上可视化了loss、acc、每一层参数的变化。以上pytorch构建的模型开源到了：https://github.com/AI-Chen/ResNet34

----
### 1.数据的处理与读取
&emsp;&emsp;关于如何将cifar-10的数据集转换为图片png的格式这里就不讲了。推广到CV其它图像处理任务所需要掌握的核心知识在于：1） torch.utils.data中Dataset类与DataLoder类对数据读取的机制；2）torchvision中transforms类对数据的增强与标准化。<br>
&emsp;&emsp;pytorch中对数据的读取主要步骤如下：
* 制作图片的索引；
* 构建Dataset子类；
* 使用Dataset子类初始号DataLoader从而返回批量的读取数据；<br>

&emsp;&emsp;首先对于已经划分好存储于data/train、data/valid的10个类别的图片数据。我使用了以下代码对它们制作索引，并将其存储于data/train.txt、data/valid.txt中。
> * *gen_txt函数* :用于获取指定文件夹下所有png图片的路径以及label。值得一提的是，这里获取png图片的路径要是针对train.py文件的相对路径，否则会找不到文件（代码i_dir = i_dir.replace('../', '')便是起到这个作用。因为在这个语句之前找到的路径是相对于gen_txt函数所在文件的。

```
# coding:utf-8
import os
'''
    为数据集生成对应的txt文件
'''

train_txt_path = '../Data/train.txt'
train_dir = '../data/train/'

valid_txt_path = '../Data/valid.txt'
valid_dir = '../data/valid/'


def gen_txt(txt_path, img_dir):
    f = open(txt_path, 'w')

    for root, s_dirs, _ in os.walk(img_dir, topdown=True):  # 获取 train文件下各文件夹名称
        for sub_dir in s_dirs:
            i_dir = os.path.join(root, sub_dir)             # 获取各类的文件夹 绝对路径
            img_list = os.listdir(i_dir)                    # 获取类别文件夹下所有png图片的路径
            i_dir = i_dir.replace('../', '')
            for i in range(len(img_list)):
                if not img_list[i].endswith('png'):         # 若不是png文件，跳过
                    continue
                label = img_list[i].split('_')[0]
                img_path = os.path.join(i_dir, img_list[i])
                line = img_path + ' ' + label + '\n'
                f.write(line)
    f.close()


if __name__ == '__main__':
    gen_txt(train_txt_path, train_dir)
    gen_txt(valid_txt_path, valid_dir)
```

&emsp;&emsp;其次，构建Dataset的子类MyDataset，用于利用上一步制作的索引来找寻图片，返回图片数据与相应label。
> * *class Dataset*：来看一下它的源码：
```
class Dataset(object):
        """An abstract class representing a Dataset.
        All other datasets should subclass it. All subclasses should override
        ``__len__``, that provides the size of the dataset, and ``__getitem__``,
        supporting integer indexing in range from 0 to len(self) exclusive.
        """
        def __getitem__(self, index):
        raise NotImplementedError
        def __len__(self):
        raise NotImplementedError
        def __add__(self, other):
        return ConcatDataset([self, other])
```
这里关注的重点是\__getitem__函数。getitem 接收一个 index，然后返回图片数据和标签，这个index 通常指的是一个 list 的 index，这个 list 的每个元素就包含了图片数据的路径和标签信息。在这一次的任务中，这个list可以由我们所制作txt形式的索引文件得到。
* *class MyDataset*：再来看一下为本次任务所写的继承了Dataset的Mydataset类：
```
from PIL import Image
from torch.utils.data import Dataset
import numpy as np
import torch
from torch.autograd import Variable
import os
import matplotlib.pyplot as plt
class MyDataset(Dataset):
    def __init__(self, txt_path, transform = None, target_transform = None):
        fh = open(txt_path, 'r')
        imgs = []
        for line in fh:
            line = line.rstrip()
            words = line.split() #分割字符串为路径和label
            imgs.append((words[0], int(words[1])))
        self.imgs = imgs        # 最主要就是要生成这个list， 然后DataLoader中给index，通过getitem读取图片数据
        self.transform = transform
        self.target_transform = target_transform
    def __getitem__(self, index):
        fn, label = self.imgs[index]
        img = Image.open(fn).convert('RGB')     # 像素值 0~255，在transfrom.totensor会除以255，使像素值变成 0~1
        if self.transform is not None:
            img = self.transform(img)   # 在这里做transform，转为tensor等等
        return img, label
    def __len__(self):
        return len(self.imgs)
```
 *\__init__* 用于读取txt文件转变为一个list的数据结构。同时初始化transform（用于数据增强与标准化）。在本次任务中，所用transform的处理如下：
```
trainTransform = transforms.Compose([
    transforms.Resize(32),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    normTransform
    ])
validTransform = transforms.Compose([
    transforms.ToTensor(),
    normTransform
    ])
```
其中trainTransform表示读取训练数据时的数据增强与标准化处理。transforms.Compose表示将所需要进行的处理给 compose 起来，并且需要注意顺序。compose 起来的操作包括：<br>
&emsp;&emsp;1）*transforms.Resize(32)* 将图像大小调整为32\*32；<br><br>
&emsp;&emsp;2）*transforms.RandomCrop(32, padding=4)* 进行随机裁剪。其原理为：在裁剪之前先对图片的上下左右均填充上 4 个 pixel，值为0，即变成一个 36*36 的数据，然后再随机进行 32*32 的裁剪；<br><br>
&emsp;&emsp;3）*transforms.ToTensor()* 在这里会对数据进行 transpose，原来是 h*w*c，会经过 img = img.transpose(0,1).transpose(0, 2).contiguous()，变成 c*h*w 再除以 255，使得像素值归一化至[0-1]之间；<br><br>
&emsp;&emsp;4）*normTransform=transforms.Normalize(normMean, normStd)* 是对图像进行标准化。在进行 Normalize 时，需要设置均值和方差，这是需要自己写程序去计算的。<br><br>
&emsp;&emsp;当然，在transform中还有很多诸如翻转、变换在内的操作。他们可以根据具体的任务加到transforms.Compose中。另外，值得一提的是，对图像数据进行这些transfrom操作之后将会覆盖原始图像。<br><br>
 *\__getitem__* 根据list去读取相应的图片数据，并对数据进行transform后返回，同时返回的还有相对应的label。

&emsp;&emsp;最后，使用MyDataset初始化Dataloader后可返回一个batchsize数量的图片数据。同时，值得注意的是触达Dataloader后，会进行一个iteration的数据读取。换句话说就是读完整个数据集后，Dataloader的才算停止。以下是用DataLoader读取数据的代码：
```
# 构建MyDataset实例
train_data = MyDataset(txt_path=train_txt_path, transform=trainTransform)
valid_data = MyDataset(txt_path=valid_txt_path, transform=validTransform)

# 构建DataLoder
train_loader = DataLoader(dataset=train_data, batch_size=train_bs, shuffle=True)
valid_loader = DataLoader(dataset=valid_data, batch_size=valid_bs)

for i, data in enumerate(valid_loader):
      # 获取图片和标签
      images, labels = data
      images, labels = Variable(images), Variable(labels)
```
&emsp;&emsp;以上就是读取数据的一个完整过程。

### 2.ResNet34的构建
&emsp;&emsp;模型的构建包括模型的定义，模型参数初始化方法，模型的保存和加载，模型的 finetune(本质上还是模型权值初始化)等几部分。<br>
&emsp;&emsp;首先是模型的构建（这里以我构建的ResNet34为例）

### 3.损失函数、优化器、超参数设置
&emsp;&emsp;

### 4.模型的训练
&emsp;&emsp;

### 5.检测模型（可视化）
&emsp;&emsp;

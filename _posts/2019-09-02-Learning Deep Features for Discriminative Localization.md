---
layout: post
title: FULLY CONVOLUTIONAL MULTI-CLASS MULTIPLE
categories: Learning Deep Features for Discriminative Localization
tags: 方法
author: Chen
description: 尽管只在图像级别的标签上训练，CNN也有着显著的对象定位能力
---

**摘要**：有很多研究表明，尽管图像分类任务中没有对物体的位置进行监督，但是CNN的各层实际上有在卷积中定位对象的显著能力。但是这种能力在图像分类中的全连接层中完全丧失。本篇文章探究了使用全局平均池化层去替换全连接层使得CNN的这种定位能力得以保留的方法。实验表明，这种做法可以使得CNN仅在图像级别的标签训练后就具有定位物体位置的能力。这一能力可以应用与各种计算机视觉中的各种任务。

---

### 1、背景简述
&emsp;&emsp;Zhou等[1]最近的研究表明，尽管没有对物体的位置进行监督，但各层卷积神经网络（CNN）的卷积单元实际上表现为物体探测器。尽管具有在卷积层中定位对象的这种显着能力，但是当这种能力丧失于全连接层。 为了保留这种能力，[2]中将全连接层用全局平均池化代替。全局平均池化层可以将这种定位对象的能力保留到最后一层。在这篇文章中，作者提出了CAMs（class activation maps ）的方法强化了这种能力，不仅仅是定位对象，更可以开始准确识别图像的哪些区域更具判别力。

---

### 2、class activation maps
&emsp;&emsp;我们来看一下这一个方法是怎么得到图像中最具判别力的区域的。如下图：<br><br>
![CAMs模型](/assets/images/CNN_map/1.jpg)<br><br>
&emsp;&emsp;给定一个图像，经过CNN的网络的提取之后，在进入全局平均池化之前，得到了一个具有很多个通道数的特征图。全局平均池化的操作相当于分别把每个通道上所有位置处的数值求平均值。为了得到最后的预测结果。在全局平均池化的基础上，加上一个softlayer层得到最后的输出结果。
&emsp;&emsp;如图，softmax最后输出的概率中有一个是代表着狗（Australian terrier）的概率。这个概率由各个通道全局平均池化得到的数值加权求和再经过softmax得到。那么，这里进行加权求和时的这个权值意义重大。它代表这进入全局平均池化前的特征图中的各个通道的特征图对判别最后结果的重要程度。这样我们把这个权值与其对应的通道的特征图相乘再求和就能得到如图所示的图像中最具判别力的区域。图中可以看到，狗的最具判别力的区域集中在腿和头上。
&emsp;&emsp;那么，CNN具有定位物体最具判别力的区域的能力有什么实际的用呢？这是我们接下来要讲述的（由于我只研究弱监督，我只看了弱监督的应用部分。论文中还有其他应用）

---

### 3、Weakly-supervised Object Localization
&emsp;&emsp;我们知道，目标检测中需要用到的标注是一个一个的方框。它表示了对象的位置与范围。而现在，我们只需要使用图像级别的标注便可以对目标对象进行定位。具体的方法是将小于等于CAM中百分之20的区域去除，然后根据连通性找到剩下区域中最大的连通区域并打上方框标记。下面是在ILSVRC 验证集与测试集上的结果：<br><br>
![结果1](/assets/images/CNN_map/3.jpg)<br><br>
![结果2](/assets/images/CNN_map/4.jpg)<br><br>
&emsp;&emsp;值得注意的是作者发现，当GAP之前的最后一个卷积层具有更高的空间分辨率时，网络的定位能力得到改善。所以上述实验的各框架的CNN最后的一个卷积层都被去掉了，从而使得最后的特征图的空间分辨率为14*14。同时，在送入全局平均池化层之前，作者加入了一个卷积核大小为3，步长为1的卷积层。
&emsp;&emsp;另外一点是，实验还对比了使用全局平均池化层（GAP）与全局最大池化层（GMP）之间的差异。结果表明，使用全局平均池化比全局最大池化在定位效果上要好。
